{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "#Img Augment\n",
    "\n",
    "#import imgaug as ia\n",
    "#import imgaug.augmenters as iaa\n",
    "#from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from torchvision import models\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import transforms as T\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from dataload import xml_to_csv,PetData,Sub_region_train,Sub_region\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Loading data\n",
    "#root_path=\"D:/Dataset/Pet_Data/\"\n",
    "#root_path=\"D:/Dataset/Pet_Data/\"\n",
    "root_path=\"D:/Dataset/Oxford\"\n",
    "\n",
    "img_path=os.path.join(root_path,\"images\")\n",
    "annotation_path=os.path.join(root_path,\"annotations/xmls\")           \n",
    "annots = glob.glob(annotation_path+\"/*.xml\")\n",
    "\n",
    "seed=0\n",
    "df=xml_to_csv(annots,img_path)\n",
    "df.head()\n",
    "\n",
    "## Make Balanced Dataset (To save time, but don't do this in real research!!)\n",
    "g = df.groupby('target')\n",
    "balanced_df = pd.DataFrame(g.apply(lambda x: x.sample(g.size().min(),random_state=seed).reset_index(drop=True),))\n",
    "train, test = train_test_split(balanced_df, test_size=0.2,random_state=seed)\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "train_ds = PetData(train, train=True)\n",
    "valid_ds= PetData(test, train=True)\n",
    "def collate_fn(batch):\n",
    "    return zip(*batch)\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE\n",
    "                                       , collate_fn=collate_fn,shuffle=False)\n",
    "valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=BATCH_SIZE\n",
    "                                       , collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 958, 0: 942})\n",
      "Counter({0: 246, 1: 230})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(train.target))\n",
    "from collections import Counter\n",
    "print(Counter(test.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "#Loading Pretrained Network\n",
    "model = models.alexnet(pretrained=True)\n",
    "model.classifier[6]=nn.Linear(4096,3)\n",
    "model.load_state_dict(torch.load(\"models/epoch_46\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training SVM\n",
    "\n",
    "## Extracting Ground Truth Samples for Each Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for class\n",
    "device=\"cuda\"\n",
    "def get_gt_ft(tgt_class,model,dataset,device):\n",
    "    cnn_transforms=nn.Upsample((224,224))\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    gt_fts=[]\n",
    "    for i,(img,bboxes) in  tqdm(enumerate(dataset)):\n",
    "        for (x1,y1,x2,y2,label) in bboxes:\n",
    "            if label==tgt_class:\n",
    "                cropped_img=(img[:,int(y1):int(y2),int(x1):int(x2)])\n",
    "                cropped_img=cnn_transforms(cropped_img.unsqueeze(0))\n",
    "                cropped_img=cropped_img.to(device)\n",
    "                gt_ft=model.classifier[0:-2](torch.flatten((model.avgpool(model.features(cropped_img))),1))\n",
    "                gt_fts.append(gt_ft.cpu())\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "    gt_fts=torch.stack(gt_fts)\n",
    "    return gt_fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gt_ft_cats=get_gt_ft(0,model_ft,train_ds,\"cuda\")\n",
    "#torch.save(gt_ft_cats,\"gf_cats.pt\")\n",
    "\n",
    "#gt_ft_dogs=get_gt_ft(1,model_ft,train_ds,\"cuda\")\n",
    "#torch.save(gt_ft_dogs,\"gf_dogs.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=0\n",
    "valid1, valid2 = train_test_split(valid_ds, test_size=0.5,random_state=seed)\n",
    "BATCH_SIZE = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import iou\n",
    "def neg_sample(proposed_regions,bboxes):\n",
    "    ''' \n",
    "    if iou below 0.3 it is considered as negative sample for training SVM\n",
    "    '''\n",
    "    \n",
    "    iou_threshold=0.3\n",
    "    for region in proposed_regions:\n",
    "        max_iou=0\n",
    "        region['labels']=-1\n",
    "        region_tensor=torch.tensor((region['rect'][0],region['rect'][1],region['rect'][0]+region['rect'][2],region['rect'][1]+region['rect'][3]))\n",
    "        for bbox in bboxes:\n",
    "            box_tensor=torch.tensor((bbox[0],bbox[1],bbox[2],bbox[3]))\n",
    "            cur_iou=iou.torch_getIOU(region_tensor,box_tensor)\n",
    "            if max_iou<cur_iou:\n",
    "                max_iou=cur_iou\n",
    "        region['iou']=max_iou\n",
    "    regions_df=pd.DataFrame.from_dict(proposed_regions)\n",
    "    regions_df=regions_df[regions_df['iou']<0.3]\n",
    "    return regions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from utills import ssearch,misc\n",
    "from utills.misc import create_label,balance_df\n",
    "'''\n",
    "device='cuda'\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "x_ft=[]\n",
    "y_label=[]    \n",
    "\n",
    "\n",
    "for img_batch_idx,(img_tuple,bbox) in tqdm(enumerate(valid1)):\n",
    "    acc_regions=None\n",
    "    avg_tloss_pimage=0\n",
    "\n",
    "    img_lbl, regions = ssearch.selective_search(img_tuple.numpy().transpose(1,2,0), scale=100, sigma=0.8, min_size=20)\n",
    "\n",
    "    regions=neg_sample(regions,bbox)  #Consider IOU<0.3 as negative sapmle\n",
    "    #Create Dataset of proposed regions\n",
    "    region_ds=Sub_region(regions,img_tuple,pil=False)\n",
    "    region_dl=DataLoader(region_ds,batch_size=32)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx,(img_tuple,label) in enumerate(region_dl):\n",
    "            img_tuple=img_tuple.to(device)\n",
    "            ft_vec=model.classifier[0:-2](torch.flatten((model.avgpool(model.features(img_tuple))),1))\n",
    "            output=model.classifier[-2:](ft_vec.clone())\n",
    "            outmax=torch.max(output.data,1).indices.cpu()\n",
    "            b = outmax != 0\n",
    "            indices = b.nonzero()\n",
    "            \n",
    "            if (len(indices) !=0):                             #Cache False Positive as Hard Negative Sample\n",
    "                sampled_fn=img_tuple[indices.reshape(-1)]\n",
    "                out=ft_vec[indices.reshape(-1)].cpu().numpy()\n",
    "                outmax=outmax[indices.reshape(-1)].numpy()\n",
    "                x_ft.append(out)\n",
    "                y_label.append(outmax)\n",
    "    \n",
    "\n",
    "x_ft=np.concatenate(x_ft)\n",
    "y_label=np.concatenate(y_label)\n",
    "np.save(\"hard_negative_cat.npy\",x_ft[np.where(y_label ==1)])\n",
    "np.save(\"hard_negative_dog.npy\",x_ft[np.where(y_label ==2)])\n",
    "'''\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SVM for each_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pos=torch.load(\"gf_cats.pt\").squeeze(1).detach().numpy()\n",
    "cat_neg=torch.tensor(np.load(\"hard_negative_1.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cat=np.concatenate([cat_pos,cat_neg])\n",
    "y_cat=np.concatenate([np.ones(cat_pos.shape[0]),np.zeros(cat_neg.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1468\n",
      "         1.0       1.00      1.00      1.00       942\n",
      "\n",
      "    accuracy                           1.00      2410\n",
      "   macro avg       1.00      1.00      1.00      2410\n",
      "weighted avg       1.00      1.00      1.00      2410\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "x_cat,y_cat = shuffle(x_cat,y_cat, random_state=0)\n",
    "clf_cat = svm.SVC(kernel='linear',max_iter=1000,probability=True)\n",
    "clf_cat.fit(x_cat, y_cat)\n",
    "end=time.time()\n",
    "print(classification_report(y_cat, clf_cat.predict(x_cat)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time 20.374638080596924\n"
     ]
    }
   ],
   "source": [
    "print(f\"Elapsed Time {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_pos=torch.load(\"gf_dogs.pt\").squeeze(1).detach().numpy()\n",
    "dog_neg=torch.tensor(np.load(\"hard_negative_2.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dog=np.concatenate([dog_pos,dog_neg])\n",
    "y_dog=np.concatenate([np.ones(dog_pos.shape[0]),np.zeros(dog_neg.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      3213\n",
      "         1.0       0.92      0.95      0.93       958\n",
      "\n",
      "    accuracy                           0.97      4171\n",
      "   macro avg       0.95      0.96      0.96      4171\n",
      "weighted avg       0.97      0.97      0.97      4171\n",
      "\n",
      "Elapsed Time 76.66726350784302\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "x_dog,y_dog = shuffle(x_dog,y_dog, random_state=0)\n",
    "clf_dog = svm.SVC(kernel='linear',max_iter=1000,probability=True)\n",
    "\n",
    "clf_dog.fit(x_dog, y_dog)\n",
    "print(classification_report(y_dog, clf_dog.predict(x_dog)))\n",
    "end=time.time()\n",
    "print(f\"Elapsed Time {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'cat_svm.sv'\n",
    "pickle.dump(clf_cat, open(filename, 'wb'))\n",
    "filename = 'dog_svm.sv'\n",
    "pickle.dump(clf_dog, open(filename, 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_cat = pickle.load(open(\"cat_svm.sv\", 'rb'))\n",
    "clf_dog = pickle.load(open(\"dog_svm.sv\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating/Testing Model  (We are nearly there!!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "device=\"cuda\"\n",
    "model.eval()\n",
    "model.to(device)\n",
    "COLOR=['red','blue']\n",
    "LABEL=['cat','dog']\n",
    "nms_thresh=0.5\n",
    "for img_batch_idx,(img_tuple,_) in tqdm(enumerate(valid2)):\n",
    "    acc_regions=None\n",
    "    avg_tloss_pimage=0\n",
    "\n",
    "    img_lbl, regions = ssearch.selective_search(img_tuple.numpy().transpose(1,2,0), scale=100, sigma=0.8, min_size=20)\n",
    "    for region in regions:\n",
    "        region['labels']=-1\n",
    "        region_tensor=torch.tensor((region['rect'][0],region['rect'][1],region['rect'][0]+region['rect'][2],region['rect'][1]+region['rect'][3]))\n",
    "    regions=pd.DataFrame.from_dict(regions)\n",
    "    \n",
    "    #Create Dataset of proposed regions\n",
    "    region_ds=Sub_region(regions,img_tuple,pil=False,return_idx=True)\n",
    "    region_dl=DataLoader(region_ds,batch_size=32)    \n",
    "    detected_region_idx=[]\n",
    "    conf_score=[]\n",
    "    labels=[]\n",
    "    with torch.no_grad():\n",
    "        region_idx=0\n",
    "        for batch_idx,(region_tuple,_,ds_index) in enumerate(region_dl):\n",
    "            region_tuple=region_tuple.to(device)\n",
    "            ft_vec=model.classifier[0:-2](torch.flatten((model.avgpool(model.features(region_tuple))),1))\n",
    "            prob_cat=clf_cat.predict_proba(ft_vec.cpu().numpy())[:,1]\n",
    "            prob_dog=clf_dog.predict_proba(ft_vec.cpu().numpy())[:,1]\n",
    "            pred_cat=clf_cat.predict(ft_vec.cpu().numpy())\n",
    "            pred_dog=clf_dog.predict(ft_vec.cpu().numpy())\n",
    "            \n",
    "            output=[]\n",
    "            detected=[]\n",
    "            for idx,(a,b) in enumerate(zip(prob_cat,prob_dog)): \n",
    "                max_val=max(a,b)\n",
    "                label=np.argmax([a,b])\n",
    "                \n",
    "                if max_val<0.5:\n",
    "                    continue\n",
    "                else:\n",
    "                    detected_region_idx.append(ds_index[idx].item())        \n",
    "                    conf_score.append(max_val)\n",
    "                    labels.append(label)\n",
    "    det_region=regions.iloc[detected_region_idx].reset_index()\n",
    "    det_region['conf_score']=conf_score\n",
    "    det_region['labels']=labels\n",
    "    \n",
    "    det_region=det_region.sort_values([\"conf_score\"], ascending = False)\n",
    "    \n",
    "    det_region.drop_duplicates(subset =\"rect\",\n",
    "                         keep = False, inplace = True)\n",
    "    det_region = det_region.drop(det_region[det_region.conf_score < 0.7].index)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    final_df=None\n",
    "    class_df = det_region.groupby('labels')    \n",
    "    dfs=[class_df.get_group(x) for x in class_df.groups]\n",
    "    \n",
    "\n",
    "    for df in dfs:\n",
    "        print(df)\n",
    "        idx=0\n",
    "        while True:\n",
    "            if idx==len(df):\n",
    "                break\n",
    "            anc_box=df.iloc[idx].rect\n",
    "            flag=[False]*len(df)\n",
    "            for row_idx_2 in range(idx+1,len(df)):\n",
    "                if iou.torch_getIOU(cvtbbox(anc_box),cvtbbox(df.iloc[row_idx_2].rect)) > 0.5:\n",
    "                    flag[row_idx_2]=True\n",
    "            df=df.drop(df.index[np.where(flag)[0]])\n",
    "\n",
    "            idx+=1\n",
    "\n",
    "        if final_df is None:\n",
    "            final_df=df\n",
    "        else:\n",
    "            final_df=final_df.append(df)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    ax.imshow(img_tuple.numpy().transpose((1,2,0))*0.5+0.5)\n",
    "    for data in final_df.iterrows():\n",
    "      #  print(data)\n",
    "        rect=data[1]['rect']\n",
    "        xy=rect[0],rect[1]\n",
    "        width=rect[2]\n",
    "        height=rect[3]\n",
    "\n",
    "        ax.add_patch(\n",
    "         patches.Rectangle(\n",
    "            xy,\n",
    "            width,\n",
    "            height,\n",
    "            edgecolor = COLOR[data[1][\"labels\"]],\n",
    "            fill=False,\n",
    "            linewidth=6,\n",
    "         label=LABEL[data[1][\"labels\"]) )\n",
    "    ax.legend()\n",
    "    fig.show()\n",
    "    break\n",
    "    if img_batch_idx==5:\n",
    "        break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>rect</th>\n",
       "      <th>size</th>\n",
       "      <th>labels</th>\n",
       "      <th>conf_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>443</td>\n",
       "      <td>(75, 61, 65, 96)</td>\n",
       "      <td>3276</td>\n",
       "      <td>0</td>\n",
       "      <td>0.961099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index              rect  size  labels  conf_score\n",
       "6    443  (75, 61, 65, 96)  3276       0    0.961099"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(flag)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>rect</th>\n",
       "      <th>size</th>\n",
       "      <th>labels</th>\n",
       "      <th>conf_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>443</td>\n",
       "      <td>(75, 61, 65, 96)</td>\n",
       "      <td>3276</td>\n",
       "      <td>0</td>\n",
       "      <td>0.961099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index              rect  size  labels  conf_score\n",
       "6    443  (75, 61, 65, 96)  3276       0    0.961099"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_region.rect[0]\n",
    "\n",
    "def cvtbbox(rect):\n",
    "    '''\n",
    "    \n",
    "    input:={x,y,width,height0}\n",
    "    output={x,y,x+width,y+height}\n",
    "    '''\n",
    "    \n",
    "    return (rect[0],rect[1],rect[0]+rect[2],rect[1]+rect[3])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag=[True]*len(det_region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'idxs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-300-1544e4599f13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'idxs' is not defined"
     ]
    }
   ],
   "source": [
    "idxs = np.argsort(scores)\n",
    "\n",
    "last = len(idxs) - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'idxs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-299-e3d36e77388d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0midxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlast\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miou_cross\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'idxs' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs=np.argsort(df.conf_score.values)\n",
    "last=len(idxs)-1\n",
    "idxs = np.delete(idxs, np.concatenate(([last], np.where(iou_cross > 0.5)[0])))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=None\n",
    "iou_cross=np.zeros((len(det_region),len(det_region)))\n",
    "class_df = det_region.groupby('labels')    \n",
    "dfs=[class_df.get_group(x) for x in class_df.groups]\n",
    "\n",
    "\n",
    "for df in dfs:\n",
    "    idx=0\n",
    "    while True:\n",
    "        if idx==len(df):\n",
    "            break\n",
    "        anc_box=df.iloc[idx].rect\n",
    "        flag=[False]*len(df)\n",
    "        for row_idx_2 in range(idx+1,len(df)):\n",
    "            if iou.torch_getIOU(cvtbbox(anc_box),cvtbbox(df.iloc[row_idx_2].rect)) > 0.5:\n",
    "                flag[row_idx_2]=True\n",
    "        df=df.drop(df.index[np.where(flag)[0]])\n",
    "\n",
    "        idx+=1\n",
    "        \n",
    "    if final_df is None:\n",
    "        final_df=df\n",
    "    else:\n",
    "        final_df=final_df.append(df)\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>rect</th>\n",
       "      <th>size</th>\n",
       "      <th>labels</th>\n",
       "      <th>conf_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>443</td>\n",
       "      <td>(75, 61, 65, 96)</td>\n",
       "      <td>3276</td>\n",
       "      <td>0</td>\n",
       "      <td>0.961099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>782</td>\n",
       "      <td>(33, 0, 70, 86)</td>\n",
       "      <td>1655</td>\n",
       "      <td>0</td>\n",
       "      <td>0.559218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>442</td>\n",
       "      <td>(96, 61, 44, 72)</td>\n",
       "      <td>776</td>\n",
       "      <td>1</td>\n",
       "      <td>0.538370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>426</td>\n",
       "      <td>(75, 65, 51, 67)</td>\n",
       "      <td>1256</td>\n",
       "      <td>1</td>\n",
       "      <td>0.518518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index              rect  size  labels  conf_score\n",
       "6     443  (75, 61, 65, 96)  3276       0    0.961099\n",
       "15    782   (33, 0, 70, 86)  1655       0    0.559218\n",
       "5     442  (96, 61, 44, 72)   776       1    0.538370\n",
       "0     426  (75, 65, 51, 67)  1256       1    0.518518"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False]"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob[0]: nan\n",
      "Prob[1]: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "prob = (Y - Y.min()) / (Y.max() - Y.min())\n",
    "print('Prob[0]: %.3f' % (1-prob[0]))\n",
    "print('Prob[1]: %.3f' % (prob[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba=clf_cat.predict_proba(ft_vec.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.47684542e-04, 5.01075252e-06, 2.53650911e-05, 4.79932521e-03,\n",
       "       2.53650911e-05, 4.79932521e-03, 4.79932521e-03, 4.79932521e-03,\n",
       "       5.01075252e-06, 5.01075252e-06, 3.13608333e-05, 1.00000010e-07,\n",
       "       1.00000010e-07, 1.00000010e-07, 1.00000010e-07, 1.00000010e-07])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -4.00769497,  -5.59681672,  -4.83511319,  -2.37265206,\n",
       "        -4.83511319,  -2.37265206,  -2.37265206,  -2.37265206,\n",
       "        -5.59681672,  -5.59681672,  -4.73545603, -11.88137633,\n",
       "       -13.5403701 , -13.5403701 , -13.5403701 , -13.5403701 ])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_cat.decision_function(ft_vec.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba=clf_dog.predict_proba(ft_vec.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.09479395e-02, 2.03877238e-02, 6.57500884e-03, 1.14925359e-02,\n",
       "       6.57500884e-03, 1.14925359e-02, 1.14925359e-02, 1.14925359e-02,\n",
       "       2.03877238e-02, 2.03877238e-02, 2.55828111e-03, 1.43899765e-04,\n",
       "       3.86468262e-06, 3.86468262e-06, 3.86468262e-06, 3.86468262e-06])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1468\n",
      "         1.0       1.00      1.00      1.00       942\n",
      "\n",
      "    accuracy                           1.00      2410\n",
      "   macro avg       1.00      1.00      1.00      2410\n",
      "weighted avg       1.00      1.00      1.00      2410\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99773611e-01, 2.26389335e-04],\n",
       "       [9.99991159e-01, 8.84115010e-06],\n",
       "       [9.99958163e-01, 4.18372218e-05],\n",
       "       [9.93634773e-01, 6.36522673e-03],\n",
       "       [9.99958163e-01, 4.18372218e-05],\n",
       "       [9.93634773e-01, 6.36522673e-03],\n",
       "       [9.93634773e-01, 6.36522673e-03],\n",
       "       [9.93634773e-01, 6.36522673e-03],\n",
       "       [9.99991159e-01, 8.84115010e-06],\n",
       "       [9.99991159e-01, 8.84115010e-06],\n",
       "       [9.99948728e-01, 5.12723529e-05],\n",
       "       [9.99999900e-01, 1.00000010e-07],\n",
       "       [9.99999900e-01, 1.00000010e-07],\n",
       "       [9.99999900e-01, 1.00000010e-07],\n",
       "       [9.99999900e-01, 1.00000010e-07],\n",
       "       [9.99999900e-01, 1.00000010e-07]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_cat.predict_proba(ft_vec.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.21248113,  0.06849083, -0.35280456, -0.11286225, -0.07383667,\n",
       "        0.09714172, -0.78051244, -0.55083982,  0.44318874, -0.80631246,\n",
       "        0.45250598,  1.05494501, -0.71468614,  0.67765884, -0.0759865 ,\n",
       "        0.7400452 ,  0.88130578,  1.0113231 ,  0.82722229, -1.3941175 ,\n",
       "       -0.7551146 , -0.13120964,  0.06247758, -0.68962013, -0.19466711,\n",
       "       -0.58562162, -0.22940431, -0.13365673,  0.05053502, -0.57615244,\n",
       "       -0.28028913, -0.57200612])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.maximum(dfc,dfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax([dfc,dfd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-131-c6b03033eb68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdfd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-131-c6b03033eb68>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdfd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "[map(max,a,b) for a,b in zip(dfc,dfd)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
